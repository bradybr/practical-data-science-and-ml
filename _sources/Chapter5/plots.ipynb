{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8794e27-7581-48be-8c54-04d535c866f9",
   "metadata": {},
   "source": [
    "# Plots & Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25386a14-9f13-4d60-b101-cf9886ad5704",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Time to unleash the right side of your brain!  Truthfuly, we should have been working with plots for the last few sections way more extensively than we have.  Instead of introducing too many topics at once, we intentionally paused delving into the the visual exploration side of things so we could focus on one thing at a time.  Now that the analytical side of EDA is behind us, it's time to see how adding some visual creativity to your arsenal will pay huge dividends!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8287cec8-bee9-4bc9-949a-f896847bb5e6",
   "metadata": {},
   "source": [
    "```{figure} ../images/right_brain.png\n",
    "---\n",
    "width: 600px\n",
    "name: right-brain-fig\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdbae32-427f-49eb-b475-7f58dd78e497",
   "metadata": {},
   "source": [
    "Plots and graphs will come into play at multiple stages during the course of your project.  First, they'll aid in your EDA journey with the basic understanding of what you're working with, investigating raw features, and helping to identify if there are any potential issues in the data.  Then once you start moving into feature engineering and transformations you'll want to begin visualing the changes and relational effects between your variables.  After that, when you start getting into building models and iterating through versions, you'll need some way to visualize the progress, tuning, and performance of your candidate models.\n",
    "\n",
    "Up to this point all of the visuals and graphs you've been building are purely for your benefit.  They can be as simple and utilitarian, or as pretty as you want them to be.  The main focus during the proof of concept stages is to find a viable solution that works, so they only need to help you in that pursuit.  The next layer of visualizations you'll need to concern yourself with are external facing.\n",
    "\n",
    "During the course of a project you'll have multiple and distinct groups of people you'll need to communicate with, all at different levels of detail.  You'll have data science peers that will need to understand the low-level and technical aspects of your program.  You'll have business sponsors who just want to understand that you solved their problem in some way, and don't need all of the gory math and technical details.  And finally, you'll have executive leadership teams who want _very_ simple and high-level details of your success story so they can understand the value you're bringing to the organization.   As you'll come to find out, visual graphics are often worth a thousand words, and can go a long way in selling your story to all of these different stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aebe279-740a-4b56-838d-f8dc1e387375",
   "metadata": {},
   "source": [
    "<h3>Plotting In Python</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3232fb5-cfb5-4af4-8bc8-b1f770dad470",
   "metadata": {},
   "source": [
    "Before going too far, we need to lay out some of the most popular library options for plotting in Python.  There are many other popular ones you could choose from, but what follows is a pretty typical starting point for your foundational learning.  Expand from here and find out what works for you in practice.\n",
    "\n",
    "Take a look at the documentation and example galleries from the following to get a taste of what's possible.\n",
    "\n",
    "__<a href=\"https://matplotlib.org/\">Matplotlib</a>__ is the oldest and still the most popular plotting extension.  No question it works, and you'll find lots of online support if you need it.  In my opinion, it's a bit verbose to use as your top level administration though.  There are several packages offering better quality graphics with less code (interestingly enough, probably built on top of matplotlib...).  So the only time I'll use matplotlib these days is if it's something _extremely_ simple and I just need one or two lines of code to make it happen.  Other than that, it'll be one of these others that leverage matplotlib underneath the hood.  Your mileage may vary of course.\n",
    "\n",
    "__<a href=\"https://seaborn.pydata.org/tutorial.html\">Seaborn</a>__ is a library package built on top of matplotlib that addresses most of my gripes with matplotlib.  It's much more concise coding with better quality results.  I will absolutely use seaborn in my workflow depending on the graph I need, but it's not my primary library.  I favor what's known as the \"Grammar of Graphics\" {cite}`Wilkinson_2005`, which is an entirely novel approach to plotting that we'll get to when we discuss plotnine below.  Having said of all that, seaborn is currently being updated as we speak from it's core library to a grammar of graphics interface known as <a href=\"https://seaborn.pydata.org/tutorial/objects_interface.html\">seaborn.objects</a>.  I guess the word is out that it's a superior methodology.  I won't cover the new seaborn.objects interface here, because frankly, I haven't taken the time to learn it yet because my needs are met elsewhere.  I have a sneaking suspicion that this library is more actively being developed so I will likely check it out again after it's fully built out.\n",
    "\n",
    "__<a href=\"https://pandas.pydata.org/\">Pandas</a>__ should sound familiar to you if you've been beefing up your coding skills.  The extremely popular pandas library has plotting functionality that chains and works extremely well in any pandas workflow.  I will often use pandas plotting when I'm visualizing a single series or something very simple.  If it's more than that, I'll tend to default to my package of choice up next.\n",
    "\n",
    "__<a href=\"https://plotnine.readthedocs.io/en/v0.12.4/#\">Plotnine</a>__ is the current standard for implementing the grammar of graphics for Python.  It's modeled after the go-to R programming plotting library by Hadley Wickham, ggplot2 {cite}`ggplot2_2016`.  Since I came to Python from R, this was a no-brainer for me.  The value Hadley and team introduced and gave to the analytics community by incorporating this standardized interface cannot be overstated.  It's a super logical way to build up a plot layer by layer with exactly what you need.  It won't always be the most concise code, especially for simple plots, but once you learn the syntax you won't really mind.  Fair enough to say I'm a ggplot fan, and by extension, plotnine.  The only downsides I've run into with the plotnine implementation of the logic, is that it's missing a few of the more advanced things that ggplot in R has, and if you're looking for interactivity you may want to consider another option such as <a href=\"https://plotly.com/python/\">Plotly</a>.\n",
    "\n",
    "What follows is not intended to be a tutorial on Python plotting code or techinques, but more generally about the application of plotting methodologies in various stages of your projects.  We will mostly use the plotnine design in this book, but feel free to use whatever works for you.  That's what's important.\n",
    "\n",
    "Ok, now that we have all of that out of the way, let's talk about how we need to start thinking about plots and graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d72f8-405a-40f7-bb46-85e58bd4c3f4",
   "metadata": {},
   "source": [
    "<h3>Types of Plots</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b941ad-0518-4b59-95be-b9abbb2526a6",
   "metadata": {},
   "source": [
    "First off, you'll often see the words \"plots\" and \"graphs\" used interchangeably, but usually intended to mean the same thing.  These are simply visual graphics of some kind.  Plots more commonly refer to the techinical side of what we're doing in our application environments, and serve as a catch-all to encompass all kinds of visuals, from proper graphs to images.  Graphs will mostly be referencing the visualization of numeric or categorical data in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfa967-7676-48fc-a6f1-ffae1df7b621",
   "metadata": {},
   "source": [
    "Borrowing, and gently updating {numref}`plot-types-fig` below from the <a href=\"https://seaborn.pydata.org/tutorial.html\">Seaborn User Guide and Tutorial</a>, is about as straight forward as I've ever seen an illustration laying out the most common graphs and their uses.  There are of course others and more exotic plot types for specific purposes, such as heatmaps, area, autocorrelation plots, 3D graphs, graph networks, images, word clouds, animated/interactive, and so on, but what we'll reveiw will cover the overwhelming majority of our needs for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36672d4a-9092-4caa-815e-a4ffa4bc3e00",
   "metadata": {},
   "source": [
    "```{figure} ../images/plot_types.png\n",
    "---\n",
    "width: 500px\n",
    "name: plot-types-fig\n",
    "---\n",
    "Source: https://seaborn.pydata.org/tutorial/function_overview.html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f91627-843c-44d2-9820-01e2b1fb21d3",
   "metadata": {},
   "source": [
    "For each pillar of plot types, we'll discuss in more detail when we get to each section, but for now hopefully you can see there are really only a few different reasons you might want to display data graphically, i.e. for Relational, Distributions, and Categorical data.  That's pretty much it.\n",
    "\n",
    "You either want to compare some values in some way __(relational)__, investigate the dispersion of a data sample under study __(distributions)__, or you want to visualize __categorical__ (non numeric) data some how.  And all of the plot types under each pillar simply give you options and flexibility to respond to the exact pecularities of your actual data.  Honestly, you could probably learn 3 or 4 different types of graphs and be all set for 95% of the analytics we need to perform.  Of course we love having the flexibility and options to really dial in our graphics, but you could get by nonetheless.\n",
    "\n",
    "We'll use {numref}`plot-types-fig` as the reference to motivate our examples below.\n",
    "\n",
    "A couple of final thoughts before jumping in.\n",
    "\n",
    "1. Begin by thinking about what data you have before worrying about graphs and types of plots\n",
    "   - What are your numeric variables?  Are there categorical ones (if so, as the main feature, or secondary data that you want to use to hightlight or separate your numeric values in some way)?  Etc.\n",
    "3. Simple is _always_ better\n",
    "   - It's generally excepted that going overboard and adding too many dimensions in your graphics is not a good idea(data points, grouping, faceting, color, size, and shape aesthetics all at once)\n",
    "   - Reporting from personal experience, I can tell you it will overwhelm your non technical business people and does more harm than good\n",
    "4. There's a difference between working and exploratory, and presentation quality graphics\n",
    "   - For exploratory, if you tried something and it reveals interesting information great, if not that's ok too, just move on\n",
    "   - For presentation, do not leave anything in your graph that does not add value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d014f-d7e9-4bc9-9d40-1ea67c3155f9",
   "metadata": {},
   "source": [
    "Enough words.  It'll be easier if we get going with some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639d6ff-bb98-44a4-9a09-95c2842de9d0",
   "metadata": {},
   "source": [
    "<h3>Relational Plots</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db119c8e-09a4-47c1-adf7-47f9bae194a9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "These are probably the most common types of graphs we work with.  Relational means you have some variable of interest you'd like to compare with some other phenomenon, be it another variable(s) or time.  Sounds complicated, but it's really pretty straightforward.\n",
    "\n",
    "At the risk of unoriginality, we'll use the \"tips\" dataset to work through our examples below.  This popular dataset holds the record of tips received by a waiter over the course of several months.  Features present are the tip amount, bill total, sex/gender of the payer, if any smokers were present in the party, the day of the week, the time of day, and the size of the party.\n",
    "\n",
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf84c9-659f-4c5b-9073-2f5764812ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PydataSet Library\n",
    "from pydataset import data\n",
    "\n",
    "# Read in the \"tips\" dataset\n",
    "dat = data(\"tips\")\n",
    "dat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c54c6-055a-41b2-a29c-41ba2496440b",
   "metadata": {},
   "source": [
    "__<h5>Scatter Plots</h5>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55961d3d-a559-445a-bfa8-c5b719b70391",
   "metadata": {},
   "source": [
    "Scatter plots are excellent places to get started because they're pretty simple, and usually only a couple of variables.  While these types of plots could be used with categorical data such as Week Day on the x axis, it makes much more sense to view the relationships between numeric features.  Here we have three continuous variables in \"total_bill\", \"tip\", and \"size\".\n",
    "\n",
    "You'll come to start thinking about your data in terms of primary and secondary, and/or aesthetic variables, meaning information you could use to segment or further subclassify your data to give further contextual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5e649-0f29-4f2c-a9a8-94a796ee85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import warnings\n",
    "import plotnine as gg\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot scatterplot\n",
    "gg.ggplot(dat, gg.aes(x = 'total_bill', y = 'tip')) + gg.geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba7b0d-c2b1-4a83-b660-9b208b42798e",
   "metadata": {},
   "source": [
    "Cool.  Our first exploratory plot!  We're relating the size of each individual _tip_ amount to the overall size of their _total bill_.  So what can we see?  Maybe you noticed a nice linear trend as the total bill gets larger, generally so does the size of the tip?  Maybe you noticed a few points that do _not_ follow those same general patterns?  Like the anomaly of someone tipping over \\$5 on a \\$7 bill?\n",
    "\n",
    "Good start, but what else could we do here?  Maybe you thought about adding an additional segmentaiton _aesthetic_ using color in some way?  How about if we highlight each point by whether or not it was a male or female?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886d5b6-3a66-420b-a1f7-61bf6806b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simple scatterplot with gender color aesthetic\n",
    "gg.ggplot(dat, gg.aes(x = 'total_bill', y = 'tip', color = 'sex')) + gg.geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94230e9e-59f7-4453-8552-eaf1e887d558",
   "metadata": {},
   "source": [
    "Hmm... unfortunately looks like pretty uniform dispersion so it doesn't appear to be too informational.  What if we add linear fit trendlines for each gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170aba6b-b483-494a-8554-1d82098bb1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with lm fit\n",
    "(gg.ggplot(dat, gg.aes(x = 'total_bill', y = 'tip', color = 'sex')) +\n",
    "     gg.geom_point() +\n",
    "     gg.geom_smooth(method = \"lm\", se = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517c2d21-a490-40b5-825a-ee4de81e4a01",
   "metadata": {},
   "source": [
    "As we first suspected.  Not much difference based on the sexes; however, the up sloping trendlines do confirm what we first observed in a general up trend of tipping more as the total bill increases.\n",
    "\n",
    "Let's move on to segment, or facet, by whether or not each group was a \"smoking\" group or not, and also we'll use a coloring aesthetic to highlight the size of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e082954f-1cef-4e14-a55f-913cf2793c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with lm fit and standard errors\n",
    "(gg.ggplot(dat, gg.aes(x = 'total_bill', y = 'tip', color = 'size')) +\n",
    "     gg.geom_point() +\n",
    "     gg.geom_smooth(method = \"lm\") +\n",
    "     gg.facet_wrap('smoker'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f9c24-27cd-463d-8374-e12120cf963a",
   "metadata": {},
   "source": [
    "Anything jump out at you?  There's a ton of information in this one, but I'll leave it to you to pick it apart.\n",
    "\n",
    "Ok, we can't spend all day on scatterplots, but one more just for fun.  Maybe you had the thought to create a new variable to investigate the tip as a percentage of the total bill instead of just the raw dollar amount?  If so, nicely done.  Let's try it and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc099b33-8675-49ee-98ed-26715c6477af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tip % variable\n",
    "dat['tip_pct'] = dat.tip / dat.total_bill\n",
    "\n",
    "# Plot with \"smoker\" facet\n",
    "(gg.ggplot(dat, gg.aes(x = 'total_bill', y = 'tip_pct', color = 'tip')) +\n",
    "     gg.geom_point() +\n",
    "     gg.geom_smooth(method = \"lm\") +\n",
    "     gg.facet_wrap('smoker'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d39ec-5421-4f1d-8e9c-3f796e3e7f29",
   "metadata": {},
   "source": [
    "Whoa... the sign of the slopes flipped to negative?!?!  I thought we said as the total bill goes up, so does the tip amount???  Well that's true, it does, but as we can see the tip as a percentage of the total bill actually decreases as the bill gets larger.  So while yes it's more money, it's not keeping up on a linear scale.  Sad to see as I'm sure our waiter deserved better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34af6bb-5a05-4ba6-9104-f80224ae578d",
   "metadata": {},
   "source": [
    "Alright we need to move to some other types.  Next up, line plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06da1e7-a72a-4451-9dbc-9092436e99c9",
   "metadata": {},
   "source": [
    "__<h5>Line Plots</h5>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746541a8-7a85-4943-8fd6-61e2d13c9342",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Line plots are pretty straightforward.  These are the stuff of _time series_ data that we discussed in our data types section.  It doesn't really make sense to connect data point by point if they're independent observations that have no dependency across time.  Let's see what we're talking about by reading in a dataset from the St. Louis Federal Reserve with the following features:\n",
    "\n",
    "- DATE - Month\n",
    "- CPI - Consumer Price Index\n",
    "- PCE - Personal Consumption Expendature\n",
    "- AHW - Average Hourly Wage\n",
    "- CSI - Consumer Sentiment Index\n",
    "\n",
    "Recall from our discussion about time series data types, what you should notice straight away is that this data carries a _time_ component.  This is what allows you to connect the points in time over the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48d9f8-8d48-4374-9006-afe9793c4c94",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in FRED data from Github\n",
    "url = 'https://github.com/bradybr/practical-data-science-and-ml/blob/main/datasets/FRED.csv?raw=true'\n",
    "dat = pd.read_csv(url, sep = \"\\,\")\n",
    "dat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a18d95c-9eec-40d4-88d4-db13af139fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update DATE to datetime\n",
    "dat['DATE'] = pd.to_datetime(dat['DATE'])\n",
    "\n",
    "# Print statistical summaries\n",
    "dat.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816bfde-23a4-47ff-90bf-3e0f6f68d297",
   "metadata": {},
   "source": [
    "We can see that some of these variables are indexes, and others are one very different range scales, so let's start with just one series before getting too complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3330b-223c-4b01-8a6a-9e9481af6313",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CPI Time Series line plot\n",
    "(gg.ggplot(dat, gg.aes(x = 'DATE', y = 'CPI')) +\n",
    "    gg.geom_line(color = '#4E68EC') + \n",
    "    gg.ggtitle(\"CPI - Consumer Price Index\") +  \n",
    "    gg.theme(axis_text_x = gg.element_text(rotation = 45, hjust = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419642e-4fc0-41de-b8cb-b092e08d0121",
   "metadata": {},
   "source": [
    "Now what if we wanted to plot all 4 of the series together?  Could we do that?  Unfortunately no, not without normalizing or standardizing each individual series to be on the same scale.  Otherwise, the large values of the PCE series would overwhelm the smaller ones and you would not be able to see any variance.  There is another way we can get them all on one plot _without_ adjusting the values though, and it's called faceting.  Faceting essentially breaks out each series into it's own plot and then we set the \"scales\" parameter to \"free_y\" which allows each plot to set its own y-axis range instead of sharing.\n",
    "\n",
    "See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ebcdd9-40e1-4f91-bcc6-ffeeb4b5818c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Melt data from wide to long\n",
    "melted_dat = pd.melt(dat, id_vars = 'DATE')\n",
    "\n",
    "# Facet Plot\n",
    "(gg.ggplot(melted_dat, gg.aes(y = 'value', x = 'DATE', color = 'variable')) +\n",
    "    gg.geom_line() +\n",
    "    gg.theme(axis_text_x = gg.element_text(rotation = 45, hjust = 1)) +\n",
    "    gg.facet_wrap('variable', scales = 'free_y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50648159-85db-42e6-8fa5-9d30e2612291",
   "metadata": {},
   "source": [
    "One more for good measure.  We're jumping ahead a bit here to feature engineering and transformations, but let's see how we'd normalize each series so we could get them all on one graph.\n",
    "\n",
    "There are several ways we could do this, but we're going to keep it simple and create a normalized index out of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a3592-d9c5-4894-957b-289b14f65c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the variables to normalize\n",
    "vars = ['CPI','PCE','AHW','CSI']\n",
    "\n",
    "# Normalize by dividing by the first value of each series\n",
    "dat[vars] = dat[vars].div(dat[vars].iloc[0])\n",
    "\n",
    "# Melt data from wide to long\n",
    "melted_dat = pd.melt(dat, id_vars = 'DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d741bb-41c7-4546-b449-0e2a88c1a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Series Plot\n",
    "(gg.ggplot(melted_dat, gg.aes(y = 'value', x = 'DATE', color = 'variable')) +\n",
    "    gg.geom_line() +\n",
    "    gg.ggtitle(\"Normalized Series\") +  \n",
    "    gg.theme(axis_text_x = gg.element_text(rotation = 45, hjust = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae9c5a0-4c94-462e-9fd2-7606cdf8b0b4",
   "metadata": {},
   "source": [
    "<h3>Distribution Plots</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b94360-d348-4589-8033-74fd7f7531b4",
   "metadata": {},
   "source": [
    "Plots that show the statistical moments of the data in a distribution, or spread, of the data can be extremely helpful in understanding the behavior of our sample under study.  We'll start with the most common and cover a few lesser used as well.\n",
    "\n",
    "Continuing with the tips dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44976c-9791-4441-bd90-dd1c1396a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a5282-f6a7-41fc-92dd-79a0c2861df4",
   "metadata": {},
   "source": [
    "__<h5>Histograms</h5>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabcc620-9557-4a86-ae82-416aedeaa5c4",
   "metadata": {},
   "source": [
    "Histograms are probably the most familiar, and the most common to visualize the frequency counts of data series.  These graphs show the frequency of numerical data in the form of vertical rectangles illustrating how many times that value range was observed in the data (higher = more frequent).\n",
    "\n",
    "Let's see what the range of values looks like in our \"total_bill\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b0c66-0408-4958-b43d-f3733824a507",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Re-read in the tips data & create tip % variable againi\n",
    "dat = data(\"tips\")\n",
    "dat['tip_pct'] = dat.tip / dat.total_bill\n",
    "\n",
    "# Print summary statistics\n",
    "dat[['total_bill']].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfbf0c9-7e73-4bcf-ab3c-12f4e710bd2c",
   "metadata": {},
   "source": [
    "We can see that the average value is around \\$20 dollars, with the inner quartile range of \\$13-24.  Now let's see what this looks like plotted in a historgram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3fb17-ba8d-421c-8925-9841a9de53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "(gg.ggplot(dat, gg.aes('total_bill')) +\n",
    "     gg.geom_histogram(binwidth = 3) +\n",
    "     gg.geom_vline(xintercept = 20, color = \"blue\", size = 1.5) + \n",
    "     gg.annotate(\"rect\", xmin = 13, xmax = 24, ymin = 0, ymax = 45, alpha = 0.4, fill = \"#4E68EC\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c31166-90eb-4058-859f-e4aae095b22a",
   "metadata": {},
   "source": [
    "Nice!  That's pretty much exactly what we see.  Our data is right (positive) skewed, shown in that sweeping tail out to the right of our histogram.  It's a little hard to see the nuances of the full distribution though because of the \"coarseness\".  This is due to the number of chosen bins in the plotting function.  Histograms have a parameter called \"bins\" that you can adjust to increase or decrease the width of the discrete ranges on the x-axis.  Let's try making it a little more spread out by adjusting the \"binwidth\" parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f16390-11b6-4f1f-969f-18b9a4b13c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot historgram with more granular \"binwidth\"\n",
    "(gg.ggplot(dat, gg.aes('total_bill')) +\n",
    "     gg.geom_histogram(binwidth = 1) +\n",
    "     gg.geom_vline(xintercept = 20, color = \"blue\", size = 1.5) + \n",
    "     gg.annotate(\"rect\", xmin = 13, xmax = 24, ymin = 0, ymax = 25, alpha = 0.4, fill = \"#4E68EC\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0523a-e518-4ace-86fc-952cd561d610",
   "metadata": {},
   "source": [
    "Interesting.  See how we lost all of the aggregated groupings?  Historgrams are particular in the number of bins required to really see what's going on.  When you start wanting to see this kind of granularity, maybe you want the next kind of plot we'll look at called density plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42d73d1-daee-456e-ac46-48dae53b15b1",
   "metadata": {},
   "source": [
    "__<h5>Density Plots</h5>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d298e-4616-44ab-9bf6-c7f2359080ab",
   "metadata": {},
   "source": [
    "If the aggregated coarseness of the historgram was too much for you, maybe you're looking for a smoothed version that will nicely show the overall distribution of data.  Enter the density plot.  Here we lose the frequency counts in favor of the probability density funciton of a variable.  Sounds complicated, however the same idea applies as with the histogram where the larger more peaked areas occur more frequently.  Simple as that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549263c-32fc-49a9-872c-5d96429bb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density plot\n",
    "(gg.ggplot(dat) +\n",
    "     gg.geom_density(gg.aes('total_bill'), fill = \"#4E68EC\", alpha = .4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854bc660-bc41-4419-bd88-3b9e407c1f61",
   "metadata": {},
   "source": [
    "Let's overlay our density curve on top of our histogram and see how they compliment each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d1514-9196-40dd-afd2-12948404b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot density curve over the histogram\n",
    "(gg.ggplot(dat, gg.aes(x = \"total_bill\", y = gg.after_stat(\"density\"))) +\n",
    "     gg.geom_histogram() +\n",
    "     gg.geom_density(fill = \"#4E68EC\", alpha = .4) +\n",
    "     gg.scale_fill_discrete(guide = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b484e244-8753-443b-b7dc-95e55b31b03e",
   "metadata": {},
   "source": [
    "Very nice.  We can see the obvious differences between the two representations, but also where they share the same distributional shape.  Sometimes you don't need or want to see the frequency steps and jagged jumps, and would prefer to see the smooth curve.\n",
    "\n",
    "Now, let's take one last look by visualizing tips and total bill amounts on the same graph overlaying their individual density curves.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9d48d-cd51-4bf7-b9f8-beee9fbdad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Melt dataset from wide to long\n",
    "melted_dat = pd.melt(dat, id_vars = ['sex','smoker','day','time'])\n",
    "\n",
    "# Plot multiple density plots\n",
    "(gg.ggplot(melted_dat[~melted_dat.variable.isin(['tip_pct','size'])], gg.aes(x = 'value', color = 'variable')) +\n",
    "     gg.geom_density())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b5fdd-bdbc-40ba-90df-2732c56b3c5c",
   "metadata": {},
   "source": [
    "__<h5>Empirical Cumulative Density Function (ECDF)</h5>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f0ba1-8b56-4b8b-a22a-7c702ff8e03a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "On to another distribution function that calculates the fraction of observations that are less than or equal to a specific point in the distribution of the sample.  Probability density curves are extremely beneficial when you need to model or simulate from an observed sample (empirical) because a theoretical distribution will not fit or work.\n",
    "\n",
    "This one is easier to show than to explain so we'll illustrate by simulating playing a fair coin flipping game that either wins 1 token or losses 1 token with each flip, governed by a 50/50 bernouli distribution.\n",
    "\n",
    "Each game we'll start with 10 tokens and will consist of flipping a coin 1,000 times.  We'll simulate playing the game 100 times.  Each game will terminate either by running out of tokens if we hit zero, or by hitting the maximum number of flips set to 1,000.  For each game, we'll run a cumulative sum over all of the outcomes, then find the maximum total tokens we held at any one point in each game, and finally we'll calculate the ECDF on the maximums to understand the probabilty curve of what you could have expected to walk away with on average at your highest point.\n",
    "\n",
    "Sounds complicated, but it's actually pretty straight forward in practice.  Check it out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "2b110f20-5543-4bac-ba88-266486580544",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Game function that wins +1 or costs us -1 token with each flip of a coin\n",
    "def play_fun(start_amt = 10, n_flips = 1000, win_prob = .5):\n",
    "    flips = np.random.choice([1,-1], size = n_flips, p = [win_prob, (1 - win_prob)])\n",
    "    flips = np.insert(np.cumsum(flips) + start_amt, 0, start_amt)\n",
    "\n",
    "    # Truncate the series if we hit 0 and ran out of tokens\n",
    "    lost = [x for x,y in enumerate(flips) if y == 0]\n",
    "    \n",
    "    if len(lost) > 0:\n",
    "        flips = flips[0:lost[0] + 1, ]\n",
    "\n",
    "    return(flips)\n",
    "\n",
    "# Play the game n times and find the maximum cumulative total from each time we played the game\n",
    "n = 100\n",
    "tokens_seq = [play_fun() for i in range(0, n)]\n",
    "max_tokens = [max(x) for x in tokens_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaedbf2b-b9e8-4d79-94ff-d2d3ec0a7f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "# Calculate the empirical cummulative density function & create a dataframe\n",
    "ecdf = ECDF(max_tokens)\n",
    "ecdf_dat = pd.DataFrame({'x': ecdf.x,\n",
    "                         'y': ecdf.y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac9fc45-4825-44b6-b064-f574126adea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDF\n",
    "(gg.ggplot(ecdf_dat, gg.aes(x = 'x', y = 'y')) +\n",
    "    gg.stat_ecdf(color = \"#4E68EC\") +\n",
    "    gg.labs(x = \"Tokens\", y = \"Cummulative Probability\") +\n",
    "    gg.ggtitle(\"ECDF for the Maximum Tokens Held from \" + str(n) + \" Simulations\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd1d9fb-6173-43f0-ba30-11cc4d1e235b",
   "metadata": {},
   "source": [
    "Beautiful shape.  What's so cool about this distribution is that now we can begin to ask some questions about expected outcomes.  Want to know where you should have walked away if you wanted to make a profit?  Given some loss tolerance percentage what you could have won?  Etc.  \n",
    "\n",
    "For example, what if I am pretty risk adverse and wanted to know the probability of actually staying above where we started with 10 tokens?  Easy enough.  Just call our `ecdf()` object with the value you want to know the cummulative probability for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11fb23-3463-48d1-af95-7937f135fd9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the cumulative probability of the ecdf at the value of 10 tokens\n",
    "ecdf(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c641033-dc92-429f-878a-4f13b1a873db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "md(\"Ouch.  Looks like {}% of the time we went straight down and never sat on a profit.  I don't know about you, but that's not a game I want to play\".format(round(ecdf(10) * 100), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0716464f-158f-4151-93e8-48efeb350ff5",
   "metadata": {},
   "source": [
    "How do we interpret the graph then?  It's actually pretty simple.  The cumulative probability shows where some % of the observations were less than that value on the x-axis, and the inverse percentage is how much of the time the observations were greater than that number.\n",
    "\n",
    "Say you're actually pretty risk tolerant and you would like to know where you might want to start thinking about cashing out given a 50% chance of reaching that amount? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0a199-b82c-4e7e-ab37-17196f718919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set container for the cumulative probability we want, and find the token value that corresponds to it\n",
    "y_prob = .5\n",
    "x_val = ecdf_dat.loc[ecdf_dat.y == y_prob, 'x']\n",
    "\n",
    "# Plot CDF with 50% line indicators\n",
    "(gg.ggplot(ecdf_dat, gg.aes(x = 'x', y = 'y')) +\n",
    "    gg.stat_ecdf(color = \"#4E68EC\") +\n",
    "    gg.geom_segment(gg.aes(x = 0,\n",
    "                           xend = x_val,\n",
    "                           y = y_prob,\n",
    "                           yend = y_prob),\n",
    "                    color = 'maroon') +\n",
    "    gg.geom_segment(gg.aes(x = x_val,\n",
    "                           xend = x_val,\n",
    "                           y = 0,\n",
    "                           yend = y_prob),\n",
    "                    color = 'maroon') +\n",
    "    gg.labs(x = \"Max Tokens\", y = \"Cummulative Probability\") +\n",
    "    gg.ggtitle(\"ECDF for the Maximum Tokens Held from \" + str(n) + \" Simulations\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e31b9-94f9-4a49-aa8d-16e94ff8ef82",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "x = round(list(ecdf_dat.loc[ecdf_dat.y == .5, 'x'].values)[0])\n",
    "md(\"Above we can see above that 50% of the time you would fail to reach {} tokens, and 50% of the time you could expect to exceed it.  Definitely a game of chance, and not one of skill.\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64416a5a-22d4-49a3-8f8f-754352538c4f",
   "metadata": {},
   "source": [
    "Which makes sense if you think about it, because we started with 10 tokens and we're flipping a fair coin, so we should have approximately the same chance of losing 10 tokens as we do gaining 10!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec86f2-f3d9-40ad-a284-0aaa83132e32",
   "metadata": {},
   "source": [
    "<h3>Categorical Plots</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f673f-1f6c-4a34-92d5-379926ad07aa",
   "metadata": {},
   "source": [
    "And finally, our last grouping of plot types:  Categorical Plots.  \n",
    "\n",
    "These are exactly as they sound, plots for visualizing categorical data in some way.  Some of these will look very familiar to what we've seen already, while others may be a little new.  What they'll all have in common though is categorical aggregation or faceting in some way that allows us to segment by these non numeric groups.\n",
    "\n",
    "I see no reason to break from using the tips data at this point, so we'll carry on as we have been."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552ad76-b06f-468f-af07-914aed327e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9c1c4-27e4-4d81-99cf-6578e864aa22",
   "metadata": {},
   "source": [
    "__<h5>Bar Plots</h5>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87da138-729e-431a-8f6d-1a946727825c",
   "metadata": {},
   "source": [
    "Bar plots look very similar to histograms, the difference being here we're not spreading the frequencies of a numeric variable out by its range of values across the x-axis, but rather showing the categorical levels of a feature on the x-axis and the counts on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11846d62-5283-4778-8586-fde32399ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of categorical levels contained in the \"day\" feature\n",
    "(gg.ggplot(dat, gg.aes(x = 'day')) +\n",
    "    gg.geom_bar() +\n",
    "    gg.ggtitle(\"Frequency Counts by Day\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ee22d-207f-4b8a-86e0-2fe52123dffb",
   "metadata": {},
   "source": [
    "Of course we can also use the aggregation funtionality within the barplot to show numeric values _by_ these same levels contained within a categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208606d-2e7a-4d7d-b1d8-23ca26f26bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total summed values for \"total_bill\" by \"day\"\n",
    "(gg.ggplot(dat, gg.aes(x = 'day', y = 'total_bill')) +\n",
    "    gg.geom_bar(stat = 'identity') +\n",
    "    gg.ggtitle(\"Total Bill Amounts by Day\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e4e02-252e-4f24-9ad9-529b18a777b6",
   "metadata": {},
   "source": [
    "__<h5>Boxplots</h5>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3caa1b3-1395-4b34-9748-104b3c9bcb44",
   "metadata": {},
   "source": [
    "Boxplots are again similar to some others we've seen, namely bar plots and density plots.  We're essentially using a bar plot layout to view the statistical distribution of the values contained within a feature.  Recall the numeric quantile summaries we've been working with?  Well, these are graphical representations of these summaries laid out in a barchart.  \n",
    "\n",
    "How might this work?\n",
    "\n",
    "Curious if there's a statistical difference in tipping by day of the week?  We can use boxplots to nicely visualize the differences!  However, before we do, let's print out the numeric summaries for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622155e-f29e-4142-abaf-b208ce7b7d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics for tips by day \n",
    "dat.groupby('day')['tip'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62715522-aa5e-4029-85b3-b47bd779e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for tips by day\n",
    "(gg.ggplot(dat, gg.aes(x = 'day', y = 'tip')) +\n",
    "    gg.geom_boxplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9925e-1565-4682-afcb-b3d85fc26ed5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Nice.  The minimums and maximums are easily identifiable.  Now, remember the discussion about inner quartile range (25th-75th percentiles)?  Well those are observable in the plot as the outer horizontal lines of the boxes.  The thickest line in the middle of the box is the median value.  And see those vertical lines sticking out above and below each box?  Those are the 1.5x the IQR range we've also been discussing as an indication of the upper and lower limits for outliers.  Which leaves the dots beyond those outlier limits.  Can you guess what those are?  Outliers!  Good guess.\n",
    "\n",
    "We could also do some coloring and additional grouping and faceting if we'd like to get a little more information in one graphic, just don't forget that _simple is always better_, as things can get overly complicated super quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48ac1b-61f0-4f3b-bab1-4c80af9ff475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplot with size facet and color aesthetic by gender\n",
    "(gg.ggplot(dat, gg.aes(x = 'day', y = 'tip', color = 'sex')) +\n",
    "    gg.geom_boxplot() +\n",
    "    gg.ggtitle(\"Tips by Day, Party Size, and Gender\") +\n",
    "    gg.facet_wrap('size'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b94529-7cfe-49b2-a3ab-51d6a067dd4f",
   "metadata": {},
   "source": [
    "__<h5>Violin Plots</h5>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f14989-a5f9-4e16-a6cb-f96dcec80230",
   "metadata": {},
   "source": [
    "Next up is one of my favorite types of plots, but also unfortunately one of the least used by others.  Sad, because it's really an informative one.\n",
    "\n",
    "Let's start with throwing boxplots under the bus first.  Did you happen to notice a potential issue with boxplots?  It's ok if you did't catch it.  Yes, these plots show a graphical representation of the numeric distribution of a variable, but they can easily obsfucate the real underlying spread.  Let's show an example to make this clear.  \n",
    "\n",
    "First, we'll simulate a bimodal distribution and see what it looks like in a histogram and density curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66375a1e-ec85-4ead-b9f2-679d434d1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bimodal distribution\n",
    "x1 = np.random.beta(5, 1.5, n)\n",
    "x2 = np.random.beta(1.5, 5, n)\n",
    "X = pd.DataFrame({ 'x' : np.concatenate([x1, x2]) }) \n",
    "\n",
    "# Plot density curve over histogram\n",
    "(gg.ggplot(X, gg.aes(x = 'x', y = gg.after_stat(\"density\"))) +\n",
    "     gg.geom_histogram(binwidth = .1) +\n",
    "     gg.geom_density(fill = \"#4E68EC\", alpha = .4) +\n",
    "     gg.scale_fill_discrete(guide = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b02db1-db19-468a-867e-c797165e8ad9",
   "metadata": {},
   "source": [
    "Now, let's use the same data and print the numeric summary statistics, and then plot a boxplot and violin plot side by side to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f77347-3d21-49a8-a4c3-a268024c0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics\n",
    "X[['x']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ad74b-5e20-4f95-8f1e-dcee7cd9b65b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot a boxplot and violin plot sharing the same y-axis\n",
    "fig, axs = plt.subplots(ncols = 2, sharey = True)\n",
    "sns.boxplot(y = 'x', data = X, ax = axs[0])\n",
    "sns.violinplot(y = 'x', split = True, inner = \"quart\", cut = 0, data = X, ax = axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d1506-3254-4f18-94fd-4f97ee86b4d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Very very interesting.  Hopefully you can see the clear differences.  Would you really have been able to understand the distribution of data from the boxplot by itself?  The new violin plot clearly shows the underlying distribution much better than the boxplot does.  It's essentially a density plot turned on it's side with the quartiles overlaid.  Super informative.  \n",
    "\n",
    "This example is just a simple caution.  While boxplots are awesome and super helpful, they can also easily hide distributional information if the data is non-normal.  And this isn't to say violin plots are infallable either.  Simply understand every plot type has its strengths and weaknesses, and try not to fall in love with just one type and you'll be fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e9a7f-d097-4529-86ad-54c4401116dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Back to violin plots.  We can do some very cool things with these by splitting, coloring, and faceting.  Here's just a taste below if you wanted to see the difference in tipping percentage by gender, and whether or not they were in a party with a smoker.  It would be nearly impossible to see this same amount of information in such a succient way in a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d093b80-6ad0-42f9-b752-a75aafe0aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot split violin plot\n",
    "sns.violinplot(data = dat, x = \"smoker\", y = \"tip_pct\", hue = \"sex\", inner = \"quart\", split = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fdc2cf-0e79-4bc2-bb75-2eb11743c3e1",
   "metadata": {},
   "source": [
    "__<h5>Mosaic Plots</h5>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0c3415-58b9-460f-9487-227c532a9dd9",
   "metadata": {},
   "source": [
    "And now our final plot type we're going to show: Mosiac Plots.\n",
    "\n",
    "Mosaic plots are awesome and simple ways to plot multiple categorical variables against each other.  Under the hood, mosiac plots are leveraging what's known as _crosstabs_, which caluclate the overlapping percentages amongst the categorical groups.\n",
    "\n",
    "Let's see how it works using the sex and day variables in the tips data.  First, we show a crosstab table to illustrate the actual numbers behind the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c51422-da0d-45d5-b146-d8bc1ecb3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the crosstab table for sex and day\n",
    "pd.crosstab(dat['sex'], dat['day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc3f6fc-5d55-480b-86d2-311238aa26af",
   "metadata": {},
   "source": [
    "And now the mosaic plot, which is just a graphical representation of the crosstable counts above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346fa76-95fc-4adb-bb79-add6978d6fdb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "\n",
    "# Plot 2 feature mosaic plot\n",
    "mosaic(dat, ['sex', 'day'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54ecb01-7550-4603-953a-5a01bf3e81e0",
   "metadata": {},
   "source": [
    "<h3>What Did We Learn?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c888fa3-d6c7-4c31-bb13-92b4ea2bb009",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Another long one, I know.  But there's so many different ways to visualize your data and we wanted to try to expose you to as many useful methodologies as possible.  You'll start to get comfortable with a plotting library and syntax you prefer over time, and with practice you'll be able to quickly associate different plot types with the specifics of your data at hand.  And as you being trying these out for yourself, you'll run across problems and new details you'd like to dial in and tweak.  Google, Stack Overflow, and the library documentations will again come to your rescue.\n",
    "\n",
    "The last thought to leave you with is that you'll quickly come to realize there are many dimensions we can force into a graph, but just because we can doesn't mean we should.  Graphs should not be complicated or confusing.  The point you're trying to make should jump off the image at the viewer, and rarely should require any outside explanation.\n",
    "\n",
    "Remember, _simple is always better_.\n",
    "\n",
    "Happy plotting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
